{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saif-Al-Zarrar/FamilyMemberClassifer/blob/master/VGG-Incorrrect(BinaryCE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoTv_EKWtPwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "270077ed-1b95-4000-f730-0b836c64dcc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0qRPwE8tbmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqNAf7E0HlWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d5d919d-19bf-4d93-dc56-4a7b4453ecb0"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "#Give dataset path\n",
        "train_path = '/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train'\n",
        "validation_path = '/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Validation'\n",
        "\n",
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "\n",
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "# useful for getting number of classes\n",
        "folders = glob('/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train/*')\n",
        "print(len(folders))\n",
        "\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "# Data Augmentation\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory(validation_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# learning rate schedule\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = .5\n",
        "    drop = 0.25\n",
        "    epochs_drop = 4.0\n",
        "    schedule = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return schedule\n",
        "    \n",
        "lr_scheduler = LearningRateScheduler(step_decay, verbose=0)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               monitor='val_loss',\n",
        "                               cooldown=1,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6,\n",
        "                               min_delta=0.5)\n",
        "\n",
        "#num_epochs = 1000\n",
        "#num_batch_size = 32\n",
        "\n",
        "ES = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=18, baseline=0.95, min_delta=.5,)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/VGG/VGG_Model1-{epoch:02d}-{val_accuracy:.2f}.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, ES]\n",
        "\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "\n",
        "model.fit_generator(\n",
        "  train_set,\n",
        "  validation_data=validation_set,\n",
        "  epochs=25,\n",
        "  steps_per_epoch=5,\n",
        "  validation_steps=32,\n",
        "    callbacks=callbacks ,verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 150534    \n",
            "=================================================================\n",
            "Total params: 14,865,222\n",
            "Trainable params: 150,534\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Found 349 images belonging to 6 classes.\n",
            "Found 84 images belonging to 6 classes.\n",
            "Epoch 1/25\n",
            "5/5 [==============================] - 575s 115s/step - loss: 3.8261 - accuracy: 0.7208 - val_loss: 4.3136 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.31356, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/VGG/VGG_Model1-01-0.72.hdf5\n",
            "Epoch 2/25\n",
            "5/5 [==============================] - 536s 107s/step - loss: 4.0655 - accuracy: 0.7354 - val_loss: 4.4733 - val_accuracy: 0.7179\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 4.31356\n",
            "Epoch 3/25\n",
            "5/5 [==============================] - 557s 111s/step - loss: 3.9499 - accuracy: 0.7431 - val_loss: 4.3455 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 4.31356\n",
            "Epoch 4/25\n",
            "5/5 [==============================] - 536s 107s/step - loss: 4.5817 - accuracy: 0.7021 - val_loss: 4.1538 - val_accuracy: 0.7216\n",
            "\n",
            "Epoch 00004: val_loss improved from 4.31356 to 4.15380, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/VGG/VGG_Model1-04-0.72.hdf5\n",
            "Epoch 5/25\n",
            "5/5 [==============================] - 554s 111s/step - loss: 4.0813 - accuracy: 0.7346 - val_loss: 4.1538 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 4.15380\n",
            "Epoch 6/25\n",
            "5/5 [==============================] - 541s 108s/step - loss: 4.3254 - accuracy: 0.7188 - val_loss: 4.3455 - val_accuracy: 0.7220\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 4.15380\n",
            "Epoch 7/25\n",
            "5/5 [==============================] - 562s 112s/step - loss: 4.0691 - accuracy: 0.7354 - val_loss: 4.4733 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 4.15380\n",
            "Epoch 8/25\n",
            "5/5 [==============================] - 540s 108s/step - loss: 4.4856 - accuracy: 0.7083 - val_loss: 4.1538 - val_accuracy: 0.7235\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 4.15380\n",
            "Epoch 9/25\n",
            "5/5 [==============================] - 552s 110s/step - loss: 4.1134 - accuracy: 0.7325 - val_loss: 4.3455 - val_accuracy: 0.7216\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 4.15380\n",
            "Epoch 10/25\n",
            "5/5 [==============================] - 538s 108s/step - loss: 4.2933 - accuracy: 0.7208 - val_loss: 4.1538 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 4.15380\n",
            "Epoch 11/25\n",
            "5/5 [==============================] - 555s 111s/step - loss: 4.3494 - accuracy: 0.7176 - val_loss: 4.4733 - val_accuracy: 0.7190\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 4.15380\n",
            "Epoch 12/25\n",
            "5/5 [==============================] - 537s 107s/step - loss: 4.2293 - accuracy: 0.7250 - val_loss: 4.0899 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00012: val_loss improved from 4.15380 to 4.08989, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/VGG/VGG_Model1-12-0.72.hdf5\n",
            "Epoch 13/25\n",
            "5/5 [==============================] - 539s 108s/step - loss: 4.2098 - accuracy: 0.7261 - val_loss: 3.9940 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00013: val_loss improved from 4.08989 to 3.99403, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/VGG/VGG_Model1-13-0.72.hdf5\n",
            "Epoch 14/25\n",
            "5/5 [==============================] - 555s 111s/step - loss: 4.3894 - accuracy: 0.7146 - val_loss: 4.3136 - val_accuracy: 0.7231\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 3.99403\n",
            "Epoch 15/25\n",
            "5/5 [==============================] - 536s 107s/step - loss: 4.1134 - accuracy: 0.7325 - val_loss: 4.6011 - val_accuracy: 0.7227\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 3.99403\n",
            "Epoch 16/25\n",
            "5/5 [==============================] - 558s 112s/step - loss: 4.2933 - accuracy: 0.7208 - val_loss: 4.3136 - val_accuracy: 0.7216\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 3.99403\n",
            "Epoch 17/25\n",
            "5/5 [==============================] - 537s 107s/step - loss: 4.3254 - accuracy: 0.7188 - val_loss: 3.9940 - val_accuracy: 0.7223\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 3.99403\n",
            "Epoch 18/25\n",
            "5/5 [==============================] - 555s 111s/step - loss: 4.0868 - accuracy: 0.7346 - val_loss: 4.6011 - val_accuracy: 0.7197\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 3.99403\n",
            "Epoch 00018: early stopping\n",
            "Training completed in time:  2:44:26.479491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo4gpkNhtiZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory Path-Test\n",
        "Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Test\"\n",
        "\n",
        "# Directory Path-Train\n",
        "# Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train&Validation\"\n",
        "\n",
        "# Code to get list of sub directories in the parent directory\n",
        "sub_dir_name_list = os.listdir(Dir)\n",
        "#sub_dir_name_list\n",
        " \n",
        "# Create paths to subdirectories\n",
        "sub_dir_path_list = [os.path.join(Dir, sub_dir_name) for sub_dir_name in sub_dir_name_list]\n",
        "#sub_dir_path_list\n",
        "\n",
        "# Code to alpbetical create prefix for file names for files in sub folders\n",
        "count=1\n",
        "while True:\n",
        "    file_name_prefix_list = [sub_dir_name[0:count] for sub_dir_name in sub_dir_name_list]\n",
        "    if len(file_name_prefix_list) == len(set(file_name_prefix_list)):\n",
        "        break\n",
        "    else:\n",
        "        count=count + 1\n",
        "sub_dir_name_list.sort()\n",
        "sub_dir_path_list.sort()\n",
        "file_name_prefix_list.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMOrWZMrtkIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "Accuracy={}\n",
        "Abbu=Ali=Monis=NahidMamu=TipuMamu=Wali=0\n",
        "# model = load_model('/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel9-14-0.89.hdf5')\n",
        "\n",
        "for k in range(len(file_name_prefix_list)):\n",
        "    folder=sub_dir_path_list[k]\n",
        "    class_name= sub_dir_name_list[k]\n",
        "    file_num= len(os.listdir(folder))\n",
        "    prefix= file_name_prefix_list[k]\n",
        "    \n",
        "    for i in range(file_num):\n",
        "        \n",
        "        file_name=prefix+str(i)+\".jpg\"\n",
        "        file_path = os.path.join(os.path.join(folder, file_name))\n",
        "        #Input(=input_shape; step 1.1) image size and test(=test_image) image size should be same\n",
        "#         test_image = image.load_img(file_path, target_size = (28, 28))\n",
        "        test_image = image.load_img(file_path, target_size = (224, 224,3))\n",
        "        test_image = image.img_to_array(test_image)\n",
        "        test_image = np.expand_dims(test_image, axis = 0)\n",
        "        result = model.predict(test_image)\n",
        "        pred_mat=list(result[0])\n",
        "        \n",
        "        if pred_mat.index(max(pred_mat)) == 0 and prefix==sub_dir_name_list[0][0:len(prefix)]:\n",
        "#             prediction = class_name[0] #Model 14: 36/41\n",
        "            Abbu= Abbu +1\n",
        "            Accuracy[class_name]=Abbu/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction) \n",
        "        elif pred_mat.index(max(pred_mat))==1 and prefix==sub_dir_name_list[1][0:len(prefix)]:\n",
        "#             prediction = class_name[1] #Model 14: 9/15\n",
        "            Ali= Ali +1\n",
        "            Accuracy[class_name]=Ali/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==2 and prefix==sub_dir_name_list[2][0:len(prefix)]: \n",
        "            prediction = 'Monis' #Model 14: 38/66\n",
        "            Monis= Monis +1\n",
        "            Accuracy[class_name]=Monis/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==3 and prefix==sub_dir_name_list[3][0:len(prefix)]:\n",
        "            prediction = 'Nahid Mamu' #Model 14: 9/17\n",
        "            NahidMamu= NahidMamu +1\n",
        "            Accuracy[class_name]=NahidMamu/file_num\n",
        "#             print(prediction)                    \n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==4 and prefix==sub_dir_name_list[4][0:len(prefix)]:\n",
        "            prediction = 'Tipu Mamu' #Model 14 9/12\n",
        "            TipuMamu= TipuMamu +1\n",
        "            Accuracy[class_name]=TipuMamu/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==5 and prefix==sub_dir_name_list[5][0:len(prefix)]:\n",
        "            prediction = 'Wali' #Model 14: 9/16\n",
        "            Wali=Wali+1\n",
        "            Accuracy[class_name]=Wali/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "#         print(max(list(result[0])))\n",
        "       \n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "print(Accuracy)\n",
        "\n",
        "#VGGModel1-Test:{'Abbu': 0.926829268292683, 'Ali': 0.8666666666666667, 'Monis': 0.8947368421052632, 'Nahid Mamu': \n",
        "#                   0.7647058823529411, 'Tipu Mamu': 0.5833333333333334, 'Wali': 1.0}---Avg=0.8394\n",
        "\n",
        "#VGGModel1-Train:{'Abbu': 0.9714285714285714, 'Ali': 0.9571428571428572, 'Monis': 1.0, 'NahidMamu': 0.9436619718309859, \n",
        "#                   'TipuMamu': 0.971830985915493, 'Wali': 0.9701492537313433}---Avg=0.96903561\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}