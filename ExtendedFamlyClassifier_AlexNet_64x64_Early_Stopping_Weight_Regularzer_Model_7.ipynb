{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ExtendedFamlyClassifier_AlexNet_64x64_Early_Stopping_Weight_Regularzer-Model 7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saif-Al-Zarrar/FamilyMemberClassifer/blob/master/ExtendedFamlyClassifier_AlexNet_64x64_Early_Stopping_Weight_Regularzer_Model_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGym0vXzdRc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "be9abe79-101e-4059-cafa-8f7fc8715ca4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJN0tZ-51Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77fe9e6c-37c8-47ba-c375-24f4e567abb1"
      },
      "source": [
        "# %cd /content/gdrive/My Drive/ExtendedFamilyClassifier/Models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/ExtendedFamilyClassifier/Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-7K03Rgxfcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "67a8a997-354e-43d2-daaf-35e6d67960c1"
      },
      "source": [
        "# ! git clone https://github.com/Saif-Al-Zarrar/FamilyImage-Test-Train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FamilyImage-Test-Train'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 658 (delta 0), reused 0 (delta 0), pack-reused 653\u001b[K\n",
            "Receiving objects: 100% (658/658), 571.76 MiB | 20.15 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Checking out files: 100% (1081/1081), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3vFHc-dTos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_WqOyFzdRdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86420dd4-4ada-45d5-df75-0e52845c5fc1"
      },
      "source": [
        "from datetime import datetime\n",
        "startTime = datetime.now()\n",
        "print(\"Start Time :\",startTime, \"\\n\\n\")\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import model_from_json\n",
        "from keras.initializers import Constant\n",
        "from keras import backend as K\n",
        "from keras.layers import PReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1_l2\n",
        "from tensorflow.keras import regularizers\n",
        "# from keras.backend import common as K\n",
        "# K.set_image_dim_ordering('th')\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),strides=(4,4)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=2e-5, l2=1.5e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.5e-4)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(4096, activation='linear', activity_regularizer=regularizers.l1_l2(l1=1.5e-5, l2=1.5e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=1.2e-5, l2=1.2e-4)))\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(1000, activation='linear', activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.5e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.1e-4)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale = None,\n",
        "#                                    shear_range = 0.2,\n",
        "#                                    zoom_range = 0.2,\n",
        "#                                    horizontal_flip = True,\n",
        "#                                    validation_split=0.2)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = None,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = None)\n",
        "# test_datagen = ImageDataGenerator(rescale = None)\n",
        "\n",
        "# training_set = train_datagen.flow_from_directory('E:\\\\2 DL\\\\Alt_Data\\\\ExtendedFamily',\n",
        "#                                                  target_size = (28, 28),\n",
        "#                                                  batch_size = 32,\n",
        "#                                                  class_mode = 'categorical',\n",
        "#                                                  subset='training')\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory('/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Validation',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "# test_set = test_datagen.flow_from_directory('E:\\\\2 DL\\\\Dataset\\\\ExFam_Validation',\n",
        "#                                             target_size = (64, 64, 3),\n",
        "#                                             batch_size = 32,\n",
        "#                                             class_mode = 'categorical')\n",
        "\n",
        "\n",
        "# Train the Model\n",
        "#Save Best Model\n",
        "# checkpoint\n",
        "filepath=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel7-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# mc = ModelCheckpoint('AlexNetModel5.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=20, verbose=1)\n",
        "# ES = EarlyStopping(monitor='loss', verbose=1, mode='min', patience=0)\n",
        "# ES = EarlyStopping(monitor='loss', verbose=1, mode='min')\n",
        "# ES = EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=0, restore_best_weights=False)\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, mode='min', patience=18, restore_best_weights=False)\n",
        "# *ES = EarlyStopping(monitor='val_loss', verbose=1, mode='min', min_delta=.5, patience=12, \n",
        "#                    restore_best_weights=False, baseline=0.10)\n",
        "\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, mode='max', min_delta=.5, patience=5, \n",
        "#                    restore_best_weights=False, baseline=0.90)\n",
        "# ES = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, baseline=0.90)\n",
        "ES = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=16, baseline=0.95, min_delta=.5,)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=20, verbose=1, callbacks=[ES])\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=30, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# *model.fit(training_set, steps_per_epoch = 200, epochs=25, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=19, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "model.fit(training_set, steps_per_epoch = 200, epochs=25, verbose=1, callbacks=[ES, mc], \n",
        "          validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# (5) Train\n",
        "# model.fit(training_set, test_set, steps_per_epoch = 200, epochs=20, verbose=1, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# model.save(\"AlexNetModel2.h5\")\n",
        "\n",
        "print(\"Saved model to disk\", \"\\n\\n\")\n",
        "\n",
        "print(\"Time Taken :\",datetime.now() - startTime)\n",
        "\n",
        "#Model1: Time=2:28:14.21;; Accuracy= 0.9812;; val_accuracy=0.8445;; Epoch=10;; ChangesInAlexNet_Conv= Batch Norm, Padding=\n",
        "# 'same';; ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F));; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + \n",
        "# l2= ();l1= + l2=());  \n",
        "\n",
        "#Model2: Time=6:14:04.50;; Accuracy= 0.9802;; val_accuracy=0.8102;; Epoch=12;; ChangesInAlexNet_Conv= Batch Norm;;\n",
        "#  ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F));; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + \n",
        "# l2= ();l1= + l2=());\n",
        "\n",
        "#Model3: Time=5:36:24.00;; Accuracy= 0.9847;; val_accuracy=0.8181;; Epoch=11;; ChangesInAlexNet_Conv= Batch Norm;;\n",
        "#  ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F)); ModelCheckpoint(monitor='val_loss', mode='min', \n",
        "# save_best_only=True, verbose=1);; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + l2= ();l1= + l2=());\n",
        "\n",
        "#Model5: Time=15:10:44.663;; Accuracy= 0.9642;; val_accuracy=0.7256;; Epoch=30;; ChangesInAlexNet_Conv= Batch Norm; \n",
        "#Activation(ParaRelU);; ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F)); ModelCheckpoint(monitor='val_loss', \n",
        "# mode='min', save_best_only=True, verbose=1);; dropout = 0.4(3 FC(all-RelU));l1_l2: l1=1e-5 +l2=1e-4)= () (All-ParaReLu);\n",
        "# l1= + l2=());\n",
        "\n",
        "#Model6: Time=3:37:43.65;; Accuracy= 0.9401;; val_accuracy=0.8438;; Epoch=10(18);; ChangesInAlexNet_Conv= Batch Norm; Activation(ParaRelU);; \n",
        "# ChangesInAlexNet_FC= Regularization=ES(val_accuracy, p=10, rbw=F, baselne=0.9)); ModelCheckpoint(monitor='val_accuracy', save_best_only=True, verbose=1);; \n",
        "# dropout = 0.4(3 FC(all-ReLu));l1_l2: l1=1.5e-5 +l2=1.5e-4)= (1 Dense), l1_l2: l1=1e-5 +l2=1.5e-4)= (1 Dense), l1_l2: l1=1e-5 +l2=1e-4), \n",
        "# l1_l2: l1=1e-5 +l2=1e-4)--(All-ParaReLu); l1= + l2=());"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Time : 2020-07-16 10:42:37.191290 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "p_re_lu_1 (PReLU)            (None, 54, 54, 96)        279936    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "p_re_lu_2 (PReLU)            (None, 17, 17, 256)       73984     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "p_re_lu_3 (PReLU)            (None, 6, 6, 384)         13824     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "p_re_lu_4 (PReLU)            (None, 4, 4, 384)         6144      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "p_re_lu_5 (PReLU)            (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 24582     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 57,957,254\n",
            "Trainable params: 57,929,926\n",
            "Non-trainable params: 27,328\n",
            "_________________________________________________________________\n",
            "Found 349 images belonging to 6 classes.\n",
            "Found 84 images belonging to 6 classes.\n",
            "Epoch 1/25\n",
            "200/200 [==============================] - 1570s 8s/step - loss: 8.0391 - accuracy: 0.5013 - val_loss: 8.0452 - val_accuracy: 0.5021\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50213, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel7-01-0.50.hdf5\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 1497s 7s/step - loss: 6.1666 - accuracy: 0.7246 - val_loss: 6.7537 - val_accuracy: 0.6913\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.50213 to 0.69126, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel7-02-0.69.hdf5\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 1494s 7s/step - loss: 4.6623 - accuracy: 0.8164 - val_loss: 5.6400 - val_accuracy: 0.5953\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.69126\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 1501s 8s/step - loss: 3.4029 - accuracy: 0.8636 - val_loss: 3.4081 - val_accuracy: 0.8089\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.69126 to 0.80895, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel7-04-0.81.hdf5\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 1488s 7s/step - loss: 2.4489 - accuracy: 0.9006 - val_loss: 4.1455 - val_accuracy: 0.6805\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.80895\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 1491s 7s/step - loss: 2.0232 - accuracy: 0.9043 - val_loss: 2.1164 - val_accuracy: 0.7493\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.80895\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 1483s 7s/step - loss: 1.6694 - accuracy: 0.9206 - val_loss: 2.1702 - val_accuracy: 0.7848\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.80895\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 1480s 7s/step - loss: 1.5377 - accuracy: 0.9235 - val_loss: 3.1418 - val_accuracy: 0.7851\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.80895\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 1489s 7s/step - loss: 1.3457 - accuracy: 0.9425 - val_loss: 2.5547 - val_accuracy: 0.7493\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.80895\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 1479s 7s/step - loss: 1.3032 - accuracy: 0.9395 - val_loss: 3.4400 - val_accuracy: 0.7251\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.80895\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 1496s 7s/step - loss: 1.1508 - accuracy: 0.9510 - val_loss: 2.4316 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.80895 to 0.85960, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel7-11-0.86.hdf5\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 1481s 7s/step - loss: 1.1350 - accuracy: 0.9564 - val_loss: 2.9793 - val_accuracy: 0.5960\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.85960\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 1486s 7s/step - loss: 1.1865 - accuracy: 0.9489 - val_loss: 2.2766 - val_accuracy: 0.7365\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.85960\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 1486s 7s/step - loss: 1.1571 - accuracy: 0.9486 - val_loss: 2.8560 - val_accuracy: 0.7837\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.85960\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 1480s 7s/step - loss: 1.0193 - accuracy: 0.9661 - val_loss: 1.0812 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.85960\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 1494s 7s/step - loss: 0.9832 - accuracy: 0.9701 - val_loss: 2.7130 - val_accuracy: 0.8324\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.85960\n",
            "Epoch 00016: early stopping\n",
            "Saved model to disk \n",
            "\n",
            "\n",
            "Time Taken : 6:38:42.450224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfKjNxsdRdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory Path-Test\n",
        "Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Test\"\n",
        "\n",
        "# Directory Path-Train\n",
        "# Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train&Validation\"\n",
        "\n",
        "# Code to get list of sub directories in the parent directory\n",
        "sub_dir_name_list = os.listdir(Dir)\n",
        "#sub_dir_name_list\n",
        " \n",
        "# Create paths to subdirectories\n",
        "sub_dir_path_list = [os.path.join(Dir, sub_dir_name) for sub_dir_name in sub_dir_name_list]\n",
        "#sub_dir_path_list\n",
        "\n",
        "# Code to alpbetical create prefix for file names for files in sub folders\n",
        "count=1\n",
        "while True:\n",
        "    file_name_prefix_list = [sub_dir_name[0:count] for sub_dir_name in sub_dir_name_list]\n",
        "    if len(file_name_prefix_list) == len(set(file_name_prefix_list)):\n",
        "        break\n",
        "    else:\n",
        "        count=count + 1\n",
        "sub_dir_name_list.sort()\n",
        "sub_dir_path_list.sort()\n",
        "file_name_prefix_list.sort()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rxFgLkkbjRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4194a502-9350-4acd-db9d-b3b5e0d64dca"
      },
      "source": [
        "# validation_set.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abbu': 0, 'Ali': 1, 'Monis': 2, 'NahidMamu': 3, 'TipuMamu': 4, 'Wali': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-NBELgdRdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "6d857528-cdac-4a8e-9874-e3eda32e7890"
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "Accuracy={}\n",
        "Abbu=Ali=Monis=NahidMamu=TipuMamu=Wali=0\n",
        "model = load_model('/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel7-11-0.86.hdf5')\n",
        "\n",
        "for k in range(len(file_name_prefix_list)):\n",
        "    folder=sub_dir_path_list[k]\n",
        "    class_name= sub_dir_name_list[k]\n",
        "    file_num= len(os.listdir(folder))\n",
        "    prefix= file_name_prefix_list[k]\n",
        "    \n",
        "    for i in range(file_num):\n",
        "        \n",
        "        file_name=prefix+str(i)+\".jpg\"\n",
        "        file_path = os.path.join(os.path.join(folder, file_name))\n",
        "        #Input(=input_shape; step 1.1) image size and test(=test_image) image size should be same\n",
        "#         test_image = image.load_img(file_path, target_size = (28, 28))\n",
        "        test_image = image.load_img(file_path, target_size = (224, 224,3))\n",
        "        test_image = image.img_to_array(test_image)\n",
        "        test_image = np.expand_dims(test_image, axis = 0)\n",
        "        result = model.predict(test_image)\n",
        "        pred_mat=list(result[0])\n",
        "        \n",
        "        if pred_mat.index(max(pred_mat)) == 0 and prefix==sub_dir_name_list[0][0:len(prefix)]:\n",
        "#             prediction = class_name[0] #Model 14: 36/41\n",
        "            Abbu= Abbu +1\n",
        "            Accuracy[class_name]=Abbu/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction) \n",
        "        elif pred_mat.index(max(pred_mat))==1 and prefix==sub_dir_name_list[1][0:len(prefix)]:\n",
        "#             prediction = class_name[1] #Model 14: 9/15\n",
        "            Ali= Ali +1\n",
        "            Accuracy[class_name]=Ali/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==2 and prefix==sub_dir_name_list[2][0:len(prefix)]: \n",
        "            prediction = 'Monis' #Model 14: 38/66\n",
        "            Monis= Monis +1\n",
        "            Accuracy[class_name]=Monis/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==3 and prefix==sub_dir_name_list[3][0:len(prefix)]:\n",
        "            prediction = 'Nahid Mamu' #Model 14: 9/17\n",
        "            NahidMamu= NahidMamu +1\n",
        "            Accuracy[class_name]=NahidMamu/file_num\n",
        "#             print(prediction)                    \n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==4 and prefix==sub_dir_name_list[4][0:len(prefix)]:\n",
        "            prediction = 'Tipu Mamu' #Model 14 9/12\n",
        "            TipuMamu= TipuMamu +1\n",
        "            Accuracy[class_name]=TipuMamu/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==5 and prefix==sub_dir_name_list[5][0:len(prefix)]:\n",
        "            prediction = 'Wali' #Model 14: 9/16\n",
        "            Wali=Wali+1\n",
        "            Accuracy[class_name]=Wali/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "#         print(max(list(result[0])))\n",
        "       \n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "print(Accuracy)\n",
        "\n",
        "#AlexNetModel1-Test:{'Abbu': 0.926829268292683, 'Ali': 0.8666666666666667, 'Monis': 0.8947368421052632, 'Nahid Mamu': \n",
        "#                   0.7647058823529411, 'Tipu Mamu': 0.5833333333333334, 'Wali': 1.0}---Avg=0.8394\n",
        "\n",
        "#AlexNetModel1-Train:{'Abbu': 0.9714285714285714, 'Ali': 0.9571428571428572, 'Monis': 1.0, 'NahidMamu': 0.9436619718309859, \n",
        "#                   'TipuMamu': 0.971830985915493, 'Wali': 0.9701492537313433}---Avg=0.96903561\n",
        "\n",
        "#AlexNetModel2-Test:{'Abbu': 0.7317073170731707, 'Ali': 0.7333333333333333, 'Monis': 0.9473684210526315, \n",
        "# B                'Nahid Mamu': 0.8823529411764706, 'Tipu Mamu': 0.6666666666666666, 'Wali': 0.875}---Avg=0.8061\n",
        "\n",
        "#AlexNetModel2-Train:{'Abbu': 0.8428571428571429, 'Ali': 0.9571428571428572, 'Monis': 0.9879518072289156, \n",
        "#                 'NahidMamu': 0.971830985915493, 'TipuMamu': 0.9859154929577465, 'Wali': 0.9402985074626866}---Avg=0.94767\n",
        "\n",
        "#AlexNetModel3-Test:{'Abbu': 0.8536585365853658, 'Ali': 0.6666666666666666, 'Monis': 1.0, 'Nahid Mamu': 0.5294117647058824,\n",
        "#                 'Tipu Mamu': 0.3333333333333333, 'Wali': 0.875}---Avg=0.709678\n",
        "\n",
        "#AlexNetModel3-Train:{'Abbu': 0.9857142857142858, 'Ali': 0.8857142857142857, 'Monis': 1.0, 'NahidMamu': 0.647887323943662, \n",
        "#                   'TipuMamu': 0.7605633802816901, 'Wali': 0.9701492537313433}---Avg=0.8750048\n",
        "\n",
        "#AlexNetModel4-Test:{}---Avg=0.709678\n",
        "\n",
        "#AlexNetModel4-Train:{}---Avg=0.8750048\n",
        "\n",
        "#AlexNetModel5-Test:{'Abbu': 0.7073170731707317, 'Ali': 0.6666666666666666, 'Monis': 0.8070175438596491, \n",
        "#                   'Nahid Mamu': 0.8823529411764706, 'Tipu Mamu': 0.4166666666666667, 'Wali': 0.6875}---Avg=0.6946\n",
        "\n",
        "#AlexNetModel5-Train: {'Abbu': 0.8571428571428571, 'Ali': 0.8857142857142857, 'Monis': 0.9518072289156626, 'NahidMamu': 1.0, \n",
        "#                  'TipuMamu': 0.8450704225352113, 'Wali': 0.8059701492537313--Avg=0.890951\n",
        "\n",
        "#AlexNetModel6-Test:{'Abbu': 0.8292682926829268, 'Ali': 0.6666666666666666, 'Monis': 0.8771929824561403, \n",
        "                #  'NahidMamu': 0.7058823529411765, 'TipuMamu': 0.6666666666666666, 'Wali': 0.9375}---Avg=0.78053\n",
        "\n",
        "#AlexNetModel6-Train:{'Abbu': 0.9857142857142858, 'Ali': 0.9428571428571428, 'Monis': 0.963855421686747, 'NahidMamu': 0.971830985915493, \n",
        "                    # 'TipuMamu': 0.9577464788732394, 'Wali': 0.9850746268656716}---Avg=0.9678\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-596f9f40e775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mAbbu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMonis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNahidMamu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTipuMamu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWali\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel7-11-0.86.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name_prefix_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel7-11-0.86.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjGhov44dRdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da44c328-8c8e-45f8-8eef-f44b81242693"
      },
      "source": [
        "test={'Abbu': 0.8292682926829268, 'Ali': 0.6666666666666666, 'Monis': 0.8771929824561403, \n",
        "      'NahidMamu': 0.7058823529411765, 'TipuMamu': 0.6666666666666666, 'Wali': 0.9375}\n",
        "\n",
        "sum(test.values())/6\n",
        "\n",
        "# train={'Abbu': 0.9857142857142858, 'Ali': 0.9428571428571428, 'Monis': 0.963855421686747, 'NahidMamu': 0.971830985915493, 'TipuMamu': 0.9577464788732394, \n",
        "#        'Wali': 0.9850746268656716}\n",
        "\n",
        "# sum(train.values())/6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9678464903187631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT40ct_4dRdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca9526f5-327c-4ca9-d2db-22212b1b4ffd"
      },
      "source": [
        "# training_set.class_indices\n",
        "# validation_set.class_indices\n",
        "# result\n",
        "# pred_mat=list(result[0])\n",
        "# pred_mat.index(max(pred_mat))\n",
        "print(max(list(result[0])))\n",
        "pred_mat.index(max(pred_mat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9998223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSPlNlt_dRdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# from keras.models import load_model\n",
        "# import numpy as np\n",
        "# from keras.preprocessing import image\n",
        "\n",
        "# Accuracy={}\n",
        "# Abbu=Ali=Monis=NahidMamu=TipuMamu=Wali=0\n",
        "# model = load_model('AlexNetModel3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHQLL6DvdRdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights = [layer.get_weights() for layer in model.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEbe4oEDdRdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}