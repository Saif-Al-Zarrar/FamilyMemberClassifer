{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ExtendedFamlyClassifier_AlexNet_64x64_Early_Stopping_Weight_Regularzer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saif-Al-Zarrar/FamilyMemberClassifer/blob/master/ExtendedFamlyClassifier_AlexNet_64x64_Early_Stopping_Weight_Regularzer-Model%208.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGym0vXzdRc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23961e4f-4ee2-4538-ace0-98c9745bc699"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJN0tZ-51Xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77fe9e6c-37c8-47ba-c375-24f4e567abb1"
      },
      "source": [
        "# %cd /content/gdrive/My Drive/ExtendedFamilyClassifier/Models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/ExtendedFamilyClassifier/Models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-7K03Rgxfcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "67a8a997-354e-43d2-daaf-35e6d67960c1"
      },
      "source": [
        "# ! git clone https://github.com/Saif-Al-Zarrar/FamilyImage-Test-Train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FamilyImage-Test-Train'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 658 (delta 0), reused 0 (delta 0), pack-reused 653\u001b[K\n",
            "Receiving objects: 100% (658/658), 571.76 MiB | 20.15 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n",
            "Checking out files: 100% (1081/1081), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3vFHc-dTos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_WqOyFzdRdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5703ad8b-1ffe-4e37-b7c2-40ae6652f3bc"
      },
      "source": [
        "from datetime import datetime\n",
        "startTime = datetime.now()\n",
        "print(\"Start Time :\",startTime, \"\\n\\n\")\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import model_from_json\n",
        "from keras.initializers import Constant\n",
        "from keras import backend as K\n",
        "from keras.layers import PReLU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1_l2\n",
        "from tensorflow.keras import regularizers\n",
        "# from keras.backend import common as K\n",
        "# K.set_image_dim_ordering('th')\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),strides=(4,4)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n",
        "# model.add(Activation('relu'))\n",
        "model.add(PReLU(alpha_initializer=Constant(value=0.25)))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=2e-5, l2=1.5e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.5e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=5e-5, l2=5e-4)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(4096, activation='linear', activity_regularizer=regularizers.l1_l2(l1=1.5e-5, l2=1.5e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 kernel_regularizer=regularizers.l1_l2(l1=1.2e-5, l2=1.2e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=5e-5, l2=5e-4)))\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n",
        "# model.add(Dense(1000, activation='linear', activity_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.5e-4)))\n",
        "# model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "#                 kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1.1e-4)))\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='linear', \n",
        "                kernel_regularizer=regularizers.l1_l2(l1=5e-5, l2=5e-4)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# (4) Compile \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Part 2 - Fitting the CNN to the images\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale = None,\n",
        "#                                    shear_range = 0.2,\n",
        "#                                    zoom_range = 0.2,\n",
        "#                                    horizontal_flip = True,\n",
        "#                                    validation_split=0.2)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = None,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = None)\n",
        "# test_datagen = ImageDataGenerator(rescale = None)\n",
        "\n",
        "# training_set = train_datagen.flow_from_directory('E:\\\\2 DL\\\\Alt_Data\\\\ExtendedFamily',\n",
        "#                                                  target_size = (28, 28),\n",
        "#                                                  batch_size = 32,\n",
        "#                                                  class_mode = 'categorical',\n",
        "#                                                  subset='training')\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory('/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Validation',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "# test_set = test_datagen.flow_from_directory('E:\\\\2 DL\\\\Dataset\\\\ExFam_Validation',\n",
        "#                                             target_size = (64, 64, 3),\n",
        "#                                             batch_size = 32,\n",
        "#                                             class_mode = 'categorical')\n",
        "\n",
        "\n",
        "# Train the Model\n",
        "#Save Best Model\n",
        "# checkpoint\n",
        "filepath=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel8-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "mc = ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# mc = ModelCheckpoint('AlexNetModel5.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=20, verbose=1)\n",
        "# ES = EarlyStopping(monitor='loss', verbose=1, mode='min', patience=0)\n",
        "# ES = EarlyStopping(monitor='loss', verbose=1, mode='min')\n",
        "# ES = EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=0, restore_best_weights=False)\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, mode='min', patience=18, restore_best_weights=False)\n",
        "# *ES = EarlyStopping(monitor='val_loss', verbose=1, mode='min', min_delta=.5, patience=12, \n",
        "#                    restore_best_weights=False, baseline=0.10)\n",
        "\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, mode='max', min_delta=.5, patience=5, \n",
        "#                    restore_best_weights=False, baseline=0.90)\n",
        "# ES = EarlyStopping(monitor='val_loss', verbose=1, patience=10)\n",
        "# ES = EarlyStopping(monitor='val_accuracy', verbose=1, patience=10, baseline=0.90)\n",
        "ES = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=16, baseline=0.95, min_delta=.5,)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=20, verbose=1, callbacks=[ES])\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=30, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# *model.fit(training_set, steps_per_epoch = 200, epochs=25, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# model.fit(training_set, steps_per_epoch = 200, epochs=19, verbose=1, callbacks=[ES, mc], \n",
        "#           validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "model.fit(training_set, steps_per_epoch = 200, epochs=25, verbose=1, callbacks=[ES, mc], \n",
        "          validation_data = validation_set, validation_steps = 50)\n",
        "\n",
        "# (5) Train\n",
        "# model.fit(training_set, test_set, steps_per_epoch = 200, epochs=20, verbose=1, validation_split=0.2, shuffle=True)\n",
        "\n",
        "# model.save(\"AlexNetModel2.h5\")\n",
        "\n",
        "print(\"Saved model to disk\", \"\\n\\n\")\n",
        "\n",
        "print(\"Time Taken :\",datetime.now() - startTime)\n",
        "\n",
        "#Model1: Time=2:28:14.21;; Accuracy= 0.9812;; val_accuracy=0.8445;; Epoch=10;; ChangesInAlexNet_Conv= Batch Norm, Padding=\n",
        "# 'same';; ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F));; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + \n",
        "# l2= ();l1= + l2=());  \n",
        "\n",
        "#Model2: Time=6:14:04.50;; Accuracy= 0.9802;; val_accuracy=0.8102;; Epoch=12;; ChangesInAlexNet_Conv= Batch Norm;;\n",
        "#  ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F));; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + \n",
        "# l2= ();l1= + l2=());\n",
        "\n",
        "#Model3: Time=5:36:24.00;; Accuracy= 0.9847;; val_accuracy=0.8181;; Epoch=11;; ChangesInAlexNet_Conv= Batch Norm;;\n",
        "#  ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F)); ModelCheckpoint(monitor='val_loss', mode='min', \n",
        "# save_best_only=True, verbose=1);; dropout = 0.4(3 FC(all-RelU));l1_l2: l1= + l2= ();l1= + l2=());\n",
        "\n",
        "#Model5: Time=15:10:44.663;; Accuracy= 0.9642;; val_accuracy=0.7256;; Epoch=30;; ChangesInAlexNet_Conv= Batch Norm; \n",
        "#Activation(ParaRelU);; ChangesInAlexNet_FC= Regularization=ES(val_loss, p=5, rbw=F)); ModelCheckpoint(monitor='val_loss', \n",
        "# mode='min', save_best_only=True, verbose=1);; dropout = 0.4(3 FC(all-RelU));l1_l2: l1=1e-5 +l2=1e-4)= () (All-ParaReLu);\n",
        "# l1= + l2=());\n",
        "\n",
        "#Model6: Time=3:37:43.65;; Accuracy= 0.9401;; val_accuracy=0.8438;; Epoch=10(18);; ChangesInAlexNet_Conv= Batch Norm; Activation(ParaRelU);; \n",
        "# ChangesInAlexNet_FC= Regularization=ES(val_accuracy, p=10, rbw=F, baselne=0.9)); ModelCheckpoint(monitor='val_accuracy', save_best_only=True, verbose=1);; \n",
        "# dropout = 0.4(3 FC(all-ReLu));l1_l2: l1=1.5e-5 +l2=1.5e-4 (1 Dense), l1_l2: l1=1e-5 +l2=1.5e-4(2 Dense), l1_l2: l1=1e-5 +l2=1e-4), \n",
        "# l1_l2: l1=1e-5 +l2=1e-4(3 Dense)--(All-ParaReLu); l1= + l2=());\n",
        "\n",
        "#Model7: Time= 6:38:42;; Accuracy= 0.9510;; val_accuracy=0.8596;; Epoch=16(25);; ChangesInAlexNet_Conv= Batch Norm; Activation(ParaRelU);; \n",
        "# ChangesInAlexNet_FC= Regularization=ES(val_accuracy, p=16, rbw=F, baselne=0.95)); ModelCheckpoint(monitor='val_accuracy', save_best_only=True, verbose=1);; \n",
        "# dropout = 0.4(3 FC(all-ReLu));;l1_l2: l1=1.5e-5 +l2=1.5e-4 (1 Dense), l1_l2: l1=1.2e-5 +l2=1.2e-4 (2 Dense), l1_l2: l1=1e-5 +l2=1.1e-4(3 Dense)\n",
        "# --(All-ParaReLu)\n",
        "\n",
        "#Model8: Time= 6:59:46;; Accuracy= 0.8878;; val_accuracy=0.8109;; Epoch=6(25);; ChangesInAlexNet_Conv= Batch Norm; Activation(ParaRelU);; \n",
        "# ChangesInAlexNet_FC= Regularization=ES(val_accuracy, p=16, rbw=F, baselne=0.95)); ModelCheckpoint(monitor='val_accuracy', save_best_only=True, verbose=1);; \n",
        "# dropout = 0.4(3 FC(all-ReLu));;l1_l2: l1=5e-5 +l2=5e-4 (1 Dense), l1_l2: l1=5e-5 +l2=5e-4 (2 Dense), l1_l2: l1=5e-5 +l2=5e-4(3 Dense)\n",
        "# --(All-ParaReLu)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Time : 2020-07-17 06:13:48.516830 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "p_re_lu_1 (PReLU)            (None, 54, 54, 96)        279936    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "p_re_lu_2 (PReLU)            (None, 17, 17, 256)       73984     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "p_re_lu_3 (PReLU)            (None, 6, 6, 384)         13824     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "p_re_lu_4 (PReLU)            (None, 4, 4, 384)         6144      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "p_re_lu_5 (PReLU)            (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 24582     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 57,957,254\n",
            "Trainable params: 57,929,926\n",
            "Non-trainable params: 27,328\n",
            "_________________________________________________________________\n",
            "Found 349 images belonging to 6 classes.\n",
            "Found 84 images belonging to 6 classes.\n",
            "Epoch 1/25\n",
            "200/200 [==============================] - 1669s 8s/step - loss: 25.8213 - accuracy: 0.4825 - val_loss: 22.4763 - val_accuracy: 0.2038\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20384, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-01-0.20.hdf5\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 1541s 8s/step - loss: 12.0218 - accuracy: 0.6814 - val_loss: 9.1822 - val_accuracy: 0.5107\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.20384 to 0.51074, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-02-0.51.hdf5\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 1535s 8s/step - loss: 6.0827 - accuracy: 0.7521 - val_loss: 7.3499 - val_accuracy: 0.6082\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.51074 to 0.60817, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-03-0.61.hdf5\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 1532s 8s/step - loss: 4.3397 - accuracy: 0.8310 - val_loss: 4.8875 - val_accuracy: 0.6541\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.60817 to 0.65412, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-04-0.65.hdf5\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 1583s 8s/step - loss: 3.6274 - accuracy: 0.8580 - val_loss: 5.9298 - val_accuracy: 0.6311\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.65412\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 1598s 8s/step - loss: 2.9797 - accuracy: 0.8878 - val_loss: 3.2444 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.65412 to 0.81089, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-06-0.81.hdf5\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 1563s 8s/step - loss: 2.5268 - accuracy: 0.9121 - val_loss: 3.2744 - val_accuracy: 0.7372\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.81089\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 1529s 8s/step - loss: 2.3837 - accuracy: 0.9225 - val_loss: 3.4145 - val_accuracy: 0.7572\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.81089\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 1541s 8s/step - loss: 2.1750 - accuracy: 0.9336 - val_loss: 3.2086 - val_accuracy: 0.7729\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.81089\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 1538s 8s/step - loss: 2.2261 - accuracy: 0.9324 - val_loss: 2.2459 - val_accuracy: 0.7997\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.81089\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 1552s 8s/step - loss: 2.1033 - accuracy: 0.9469 - val_loss: 3.1758 - val_accuracy: 0.7113\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.81089\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 1570s 8s/step - loss: 2.2562 - accuracy: 0.9412 - val_loss: 3.0698 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.81089 to 0.82092, saving model to /content/gdrive/My Drive/ExtendedFamilyClassifier/Models/AlexNetModel8-12-0.82.hdf5\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 1610s 8s/step - loss: 2.1217 - accuracy: 0.9519 - val_loss: 3.3178 - val_accuracy: 0.7266\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.82092\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 1611s 8s/step - loss: 2.0879 - accuracy: 0.9564 - val_loss: 5.0141 - val_accuracy: 0.5645\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.82092\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 1606s 8s/step - loss: 2.1668 - accuracy: 0.9551 - val_loss: 2.7810 - val_accuracy: 0.7607\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.82092\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 1573s 8s/step - loss: 2.1796 - accuracy: 0.9615 - val_loss: 2.9319 - val_accuracy: 0.7621\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.82092\n",
            "Epoch 00016: early stopping\n",
            "Saved model to disk \n",
            "\n",
            "\n",
            "Time Taken : 6:59:45.893519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfKjNxsdRdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory Path-Test\n",
        "# Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Test\"\n",
        "\n",
        "# Directory Path-Train\n",
        "Dir=\"/content/gdrive/My Drive/ExtendedFamilyClassifier/Dataset/Train&Validation\"\n",
        "\n",
        "# Code to get list of sub directories in the parent directory\n",
        "sub_dir_name_list = os.listdir(Dir)\n",
        "#sub_dir_name_list\n",
        " \n",
        "# Create paths to subdirectories\n",
        "sub_dir_path_list = [os.path.join(Dir, sub_dir_name) for sub_dir_name in sub_dir_name_list]\n",
        "#sub_dir_path_list\n",
        "\n",
        "# Code to alpbetical create prefix for file names for files in sub folders\n",
        "count=1\n",
        "while True:\n",
        "    file_name_prefix_list = [sub_dir_name[0:count] for sub_dir_name in sub_dir_name_list]\n",
        "    if len(file_name_prefix_list) == len(set(file_name_prefix_list)):\n",
        "        break\n",
        "    else:\n",
        "        count=count + 1\n",
        "sub_dir_name_list.sort()\n",
        "sub_dir_path_list.sort()\n",
        "file_name_prefix_list.sort()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rxFgLkkbjRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4194a502-9350-4acd-db9d-b3b5e0d64dca"
      },
      "source": [
        "# validation_set.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Abbu': 0, 'Ali': 1, 'Monis': 2, 'NahidMamu': 3, 'TipuMamu': 4, 'Wali': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-NBELgdRdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5b0e581c-9040-46e7-bdc4-3183354ba173"
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "Accuracy={}\n",
        "Abbu=Ali=Monis=NahidMamu=TipuMamu=Wali=0\n",
        "model = load_model('/content/gdrive/My Drive/ExtendedFamilyClassifier/Models/Alexnet/AlexNetModel8-12-0.82.hdf5')\n",
        "\n",
        "for k in range(len(file_name_prefix_list)):\n",
        "    folder=sub_dir_path_list[k]\n",
        "    class_name= sub_dir_name_list[k]\n",
        "    file_num= len(os.listdir(folder))\n",
        "    prefix= file_name_prefix_list[k]\n",
        "    \n",
        "    for i in range(file_num):\n",
        "        \n",
        "        file_name=prefix+str(i)+\".jpg\"\n",
        "        file_path = os.path.join(os.path.join(folder, file_name))\n",
        "        #Input(=input_shape; step 1.1) image size and test(=test_image) image size should be same\n",
        "#         test_image = image.load_img(file_path, target_size = (28, 28))\n",
        "        test_image = image.load_img(file_path, target_size = (224, 224,3))\n",
        "        test_image = image.img_to_array(test_image)\n",
        "        test_image = np.expand_dims(test_image, axis = 0)\n",
        "        result = model.predict(test_image)\n",
        "        pred_mat=list(result[0])\n",
        "        \n",
        "        if pred_mat.index(max(pred_mat)) == 0 and prefix==sub_dir_name_list[0][0:len(prefix)]:\n",
        "#             prediction = class_name[0] #Model 14: 36/41\n",
        "            Abbu= Abbu +1\n",
        "            Accuracy[class_name]=Abbu/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction) \n",
        "        elif pred_mat.index(max(pred_mat))==1 and prefix==sub_dir_name_list[1][0:len(prefix)]:\n",
        "#             prediction = class_name[1] #Model 14: 9/15\n",
        "            Ali= Ali +1\n",
        "            Accuracy[class_name]=Ali/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==2 and prefix==sub_dir_name_list[2][0:len(prefix)]: \n",
        "            prediction = 'Monis' #Model 14: 38/66\n",
        "            Monis= Monis +1\n",
        "            Accuracy[class_name]=Monis/file_num\n",
        "#             count=count+1\n",
        "#             print(prediction)\n",
        "        elif pred_mat.index(max(pred_mat))==3 and prefix==sub_dir_name_list[3][0:len(prefix)]:\n",
        "            prediction = 'Nahid Mamu' #Model 14: 9/17\n",
        "            NahidMamu= NahidMamu +1\n",
        "            Accuracy[class_name]=NahidMamu/file_num\n",
        "#             print(prediction)                    \n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==4 and prefix==sub_dir_name_list[4][0:len(prefix)]:\n",
        "            prediction = 'Tipu Mamu' #Model 14 9/12\n",
        "            TipuMamu= TipuMamu +1\n",
        "            Accuracy[class_name]=TipuMamu/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "        elif pred_mat.index(max(pred_mat))==5 and prefix==sub_dir_name_list[5][0:len(prefix)]:\n",
        "            prediction = 'Wali' #Model 14: 9/16\n",
        "            Wali=Wali+1\n",
        "            Accuracy[class_name]=Wali/file_num\n",
        "#             print(prediction)\n",
        "#             count=count+1\n",
        "#         print(max(list(result[0])))\n",
        "       \n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "print(Accuracy)\n",
        "\n",
        "#AlexNetModel1-Test:{'Abbu': 0.926829268292683, 'Ali': 0.8666666666666667, 'Monis': 0.8947368421052632, 'Nahid Mamu': \n",
        "#                   0.7647058823529411, 'Tipu Mamu': 0.5833333333333334, 'Wali': 1.0}---Avg=0.8394\n",
        "\n",
        "#AlexNetModel1-Train:{'Abbu': 0.9714285714285714, 'Ali': 0.9571428571428572, 'Monis': 1.0, 'NahidMamu': 0.9436619718309859, \n",
        "#                   'TipuMamu': 0.971830985915493, 'Wali': 0.9701492537313433}---Avg=0.96903561\n",
        "\n",
        "#AlexNetModel2-Test:{'Abbu': 0.7317073170731707, 'Ali': 0.7333333333333333, 'Monis': 0.9473684210526315, \n",
        "# B                'Nahid Mamu': 0.8823529411764706, 'Tipu Mamu': 0.6666666666666666, 'Wali': 0.875}---Avg=0.8061\n",
        "\n",
        "#AlexNetModel2-Train:{'Abbu': 0.8428571428571429, 'Ali': 0.9571428571428572, 'Monis': 0.9879518072289156, \n",
        "#                 'NahidMamu': 0.971830985915493, 'TipuMamu': 0.9859154929577465, 'Wali': 0.9402985074626866}---Avg=0.94767\n",
        "\n",
        "#AlexNetModel3-Test:{'Abbu': 0.8536585365853658, 'Ali': 0.6666666666666666, 'Monis': 1.0, 'Nahid Mamu': 0.5294117647058824,\n",
        "#                 'Tipu Mamu': 0.3333333333333333, 'Wali': 0.875}---Avg=0.709678\n",
        "\n",
        "#AlexNetModel3-Train:{'Abbu': 0.9857142857142858, 'Ali': 0.8857142857142857, 'Monis': 1.0, 'NahidMamu': 0.647887323943662, \n",
        "#                   'TipuMamu': 0.7605633802816901, 'Wali': 0.9701492537313433}---Avg=0.8750048\n",
        "\n",
        "#AlexNetModel4-Test:{}---Avg=0.709678\n",
        "\n",
        "#AlexNetModel4-Train:{}---Avg=0.8750048\n",
        "\n",
        "#AlexNetModel5-Test:{'Abbu': 0.7073170731707317, 'Ali': 0.6666666666666666, 'Monis': 0.8070175438596491, \n",
        "#                   'Nahid Mamu': 0.8823529411764706, 'Tipu Mamu': 0.4166666666666667, 'Wali': 0.6875}---Avg=0.6946\n",
        "\n",
        "#AlexNetModel5-Train: {'Abbu': 0.8571428571428571, 'Ali': 0.8857142857142857, 'Monis': 0.9518072289156626, 'NahidMamu': 1.0, \n",
        "#                  'TipuMamu': 0.8450704225352113, 'Wali': 0.8059701492537313--Avg=0.890951\n",
        "\n",
        "#AlexNetModel6-Test:{'Abbu': 0.8292682926829268, 'Ali': 0.6666666666666666, 'Monis': 0.8771929824561403, \n",
        "                #  'NahidMamu': 0.7058823529411765, 'TipuMamu': 0.6666666666666666, 'Wali': 0.9375}---Avg=0.78053\n",
        "\n",
        "#AlexNetModel6-Train:{'Abbu': 0.9857142857142858, 'Ali': 0.9428571428571428, 'Monis': 0.963855421686747, 'NahidMamu': 0.971830985915493, \n",
        "                    # 'TipuMamu': 0.9577464788732394, 'Wali': 0.9850746268656716}---Avg=0.9678\n",
        "\n",
        "\n",
        "#AlexNetModel8-Test:{'Abbu': 0.7073170731707317, 'Ali': 0.8666666666666667, 'Monis': 0.8947368421052632, 'NahidMamu': 0.6470588235294118, \n",
        "                  # 'TipuMamu': 0.6666666666666666, 'Wali': 0.75}---Avg=0.75541\n",
        "\n",
        "#AlexNetModel8-Train:{'Abbu': 0.8857142857142857, 'Ali': 0.9857142857142858, 'Monis': 0.9759036144578314, 'NahidMamu': 0.971830985915493, \n",
        "                  #  'TipuMamu': 0.971830985915493, 'Wali': 0.7910447761194029}---Avg=00.93034"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Abbu': 0.8857142857142857, 'Ali': 0.9857142857142858, 'Monis': 0.9759036144578314, 'NahidMamu': 0.971830985915493, 'TipuMamu': 0.971830985915493, 'Wali': 0.7910447761194029}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjGhov44dRdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3984701d-0893-4686-de02-044f9c554f19"
      },
      "source": [
        "# test={'Abbu': 0.7073170731707317, 'Ali': 0.8666666666666667, 'Monis': 0.8947368421052632, 'NahidMamu': 0.6470588235294118, 'TipuMamu': 0.6666666666666666,\n",
        "#       'Wali': 0.75}\n",
        "\n",
        "# sum(test.values())/6\n",
        "\n",
        "train={'Abbu': 0.8857142857142857, 'Ali': 0.9857142857142858, 'Monis': 0.9759036144578314, 'NahidMamu': 0.971830985915493, 'TipuMamu': 0.971830985915493, \n",
        "       'Wali': 0.7910447761194029}\n",
        "\n",
        "sum(train.values())/6"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.930339822306132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT40ct_4dRdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca9526f5-327c-4ca9-d2db-22212b1b4ffd"
      },
      "source": [
        "# training_set.class_indices\n",
        "# validation_set.class_indices\n",
        "# result\n",
        "# pred_mat=list(result[0])\n",
        "# pred_mat.index(max(pred_mat))\n",
        "print(max(list(result[0])))\n",
        "pred_mat.index(max(pred_mat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9998223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSPlNlt_dRdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# from keras.models import load_model\n",
        "# import numpy as np\n",
        "# from keras.preprocessing import image\n",
        "\n",
        "# Accuracy={}\n",
        "# Abbu=Ali=Monis=NahidMamu=TipuMamu=Wali=0\n",
        "# model = load_model('AlexNetModel3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHQLL6DvdRdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights = [layer.get_weights() for layer in model.layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEbe4oEDdRdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}